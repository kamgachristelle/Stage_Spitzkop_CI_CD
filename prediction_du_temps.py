# -*- coding: utf-8 -*-
"""prediction du temps

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JK99rwIMd9hoHl7EvWzZB_CbtIZ1DZFf
"""

import pandas as pd
import numpy as np

# --- 1. Définition des paramètres ---
NB_LIGNES = 2057  # Nombre total de lignes (2000 + 57 erreurs supplémentaires)
NB_FAILURES_TARGET = 357 # Nous garantissons ce nombre exact d'échecs (300 initial + 57)
NB_SUCCESSES_TARGET = NB_LIGNES - NB_FAILURES_TARGET # 1700 réussites


# --- 2. Génération des données aléatoires (Succès et Échecs séparés) ---

# Données de SUCCÈS (Status = success)
data_success = pd.DataFrame({
    'status': ['success'] * NB_SUCCESSES_TARGET,
    'code_lines_changed': np.random.randint(10, 800, size=NB_SUCCESSES_TARGET)
})
data_success['pred_risk_fail'] = np.random.uniform(0.01, 0.15, size=NB_SUCCESSES_TARGET)
data_success['error_tag'] = 'None'


# Données d'ÉCHECS (Status = failure)
data_failure = pd.DataFrame({
    'status': ['failure'] * NB_FAILURES_TARGET,
    'code_lines_changed': np.random.randint(50, 900, size=NB_FAILURES_TARGET) # Les échecs peuvent avoir des changements plus grands
})
data_failure['pred_risk_fail'] = np.random.uniform(0.65, 0.95, size=NB_FAILURES_TARGET)
# Répartition des types d'erreurs
data_failure['error_tag'] = np.random.choice(['TestFail', 'DependencyError', 'Timeout', 'AuthIssue'], size=NB_FAILURES_TARGET)


# COMBINER et mélanger les jeux de données
data = pd.concat([data_success, data_failure]).reset_index(drop=True)
np.random.shuffle(data.values)


# --- 3. Ajout des colonnes temporelles et IDs (pour 2057 lignes) ---
data['workflow_id'] = [f'W-{i:04d}' for i in range(1, NB_LIGNES + 1)]
start_time_base = pd.to_datetime('2025-10-20')
# Étalement temporel
data['start_time'] = start_time_base + pd.to_timedelta(np.arange(NB_LIGNES) * 500 + np.random.randint(0, 100, NB_LIGNES), unit='s')

# Ajout des autres colonnes
data['branch_name'] = np.random.choice(['main', 'develop', 'feature-auth', 'feature-payment', 'hotfix'], size=NB_LIGNES, p=[0.3, 0.3, 0.2, 0.1, 0.1])
data['repo_name'] = np.random.choice(['repo-api', 'repo-front', 'repo-mobile'], size=NB_LIGNES, p=[0.5, 0.3, 0.2])
data['env_type'] = np.random.choice(['prod', 'staging', 'dev'], size=NB_LIGNES, p=[0.2, 0.3, 0.5])


# --- 4. Calcul de la Durée et de la Prédiction (avec corrélation) ---
# Durée réelle (proportionnelle aux lignes de code + bruit)
data['duration_s'] = (data['code_lines_changed'] * 0.8) + np.random.randint(60, 180, size=NB_LIGNES)
data['duration_s'] = data['duration_s'].astype(int)

# Prédiction de Durée
data['pred_duration_s'] = data['duration_s'] * np.random.uniform(0.95, 1.05, size=NB_LIGNES)
data['pred_duration_s'] = data['pred_duration_s'].astype(int)


# --- 5. Export du fichier CSV ---
nom_fichier = 'ci_cd_prediction_mock_2057_errors.csv'
data = data[['workflow_id', 'start_time', 'duration_s', 'status', 'pred_duration_s', 'pred_risk_fail', 'branch_name', 'repo_name', 'code_lines_changed', 'env_type', 'error_tag']]
data.to_csv(nom_fichier, index=False, date_format='%Y-%m-%d %H:%M:%S')

print(f"✅ Fichier '{nom_fichier}' de {NB_LIGNES} lignes généré avec 357 échecs garantis.")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Charger le nouveau jeu de données (2057 lignes)
df = pd.read_csv('ci_cd_prediction_mock_2057_errors.csv')

# Convertir la colonne start_time au format datetime
df['start_time'] = pd.to_datetime(df['start_time'])

print("--- Bilan de Santé des Données (2057 lignes) ---")
print(f"Nombre total de lignes : {len(df)}")
print(f"Aperçu des types de données :")
print(df.dtypes)

# Calculer le pourcentage de succès et d'échecs
status_counts = df['status'].value_counts()
status_percentages = df['status'].value_counts(normalize=True) * 100

print("\n--- Fréquence des Statuts de Pipeline ---")
print(status_counts)
print("\n--- Pourcentage ---")
print(status_percentages)

# Visualisation (Optionnel mais recommandé dans le Notebook)
plt.figure(figsize=(6, 6))
plt.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', startangle=90, colors=['#4CAF50', '#FF5722'])
plt.title('Proportion Succès vs Échec')
plt.show()

import pandas as pd
from ydata_profiling import ProfileReport
import os

# --- ÉTAPE 1 : Chargement du Fichier ---
# Assurez-vous que le fichier est présent dans l'environnement de travail de Colab
file_path = 'ci_cd_prediction_mock_2057_errors.csv' # MODIFICATION ICI : Correction du nom du fichier
df = pd.read_csv(file_path)

# --- ÉTAPE 2 : Analyse Rapide (Validation Data Manager) ---

print("--- 1. Vérification du Chargement ---")
print(f"✅ Nombre total de lignes chargées : {len(df)}")
print(f"✅ Premières lignes pour inspection :")
print(df.head())

print("\n--- 2. Vérification des Types de Colonnes ---")
print(df.dtypes)
print(f"✅ Types de 'duration_s' (cible) : {df['duration_s'].dtype} (Doit être 'int' ou 'float')")
print(f"✅ Types de 'start_time' (temps) : {df['start_time'].dtype} (Doit être 'object' ou 'datetime')")


# --- ÉTAPE 3 : Créer et Afficher le Rapport de Profilage (Rapport de Santé) ---

# Créer un rapport
profile = ProfileReport(
    df,
    title="Rapport de Profilage Colab | Validation CI/CD",
    html={'style': {'full_width': True}},
    # Options rapides de configuration (ajuster si nécessaire)
    sort=None,
    explorative=True
)

# Afficher le rapport directement dans le Notebook Colab
profile

import sys

# Installer la bibliothèque ydata-profiling
!{sys.executable} -m pip install ydata-profiling

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import pandas as pd

# Définition des variables cibles (y) et des variables explicatives (X)
colonnes_a_exclure = ['workflow_id', 'pred_duration_s', 'pred_risk_fail', 'start_time']
X = df.drop(columns=['duration_s'] + colonnes_a_exclure)
y = df['duration_s']

# Encodage des Variables Catégorielles
colonnes_categoriques = ['status', 'branch_name', 'repo_name', 'env_type', 'error_tag']
X_encoded = pd.get_dummies(X, columns=colonnes_categoriques, drop_first=True)

# Séparation en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(
    X_encoded, y, test_size=0.2, random_state=42
)
# Entraînement du modèle
model_rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
model_rf.fit(X_train, y_train)

# Évaluation (pour confirmer la performance)
y_pred_rf = model_rf.predict(X_test)
mae_rf = mean_absolute_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)

print("\n--- Nouvelle Performance Forêt Aléatoire ---")
print(f"Erreur Absolue Moyenne (MAE): {mae_rf:.2f}")
print(f"Coefficient R-carré (R2): {r2_rf:.4f}")

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score

# 1. Initialisation et entraînement du modèle Linéaire
model_linear = LinearRegression()
model_linear.fit(X_train, y_train)

# 2. Prédiction sur l'ensemble de test
y_pred_linear = model_linear.predict(X_test)

# 3. Évaluation de la performance
mae = mean_absolute_error(y_test, y_pred_linear)
r2 = r2_score(y_test, y_pred_linear)

print("\n--- Performance du Modèle de Régression Linéaire (Baseline) ---")
print(f"Erreur Absolue Moyenne (MAE): {mae:.2f}")
print(f"Coefficient R-carré (R2): {r2:.4f}")

import pandas as pd

# Créer un DataFrame pour les coefficients
coefficients = pd.Series(
    model_linear.coef_,
    index=X_train.columns
).sort_values(ascending=False)

print("\n--- Top 10 des Coefficients d'Influence (Régression Linéaire) ---")
print(coefficients.head(10))

import joblib
import os
import numpy as np

# 1. Définir le nom du fichier de sauvegarde
model_filename = 'linear_regression_final_model.joblib'

# 2. Sauvegarder l'objet Python 'model_linear' sur le disque
# Le modèle entraîné est maintenant un fichier binaire
joblib.dump(model_linear, model_filename)

print(f"✅ Modèle sauvegardé avec succès sous : '{model_filename}'")

import joblib
import pandas as pd
import numpy as np

# 1. Charger le modèle sauvegardé
model_loaded = joblib.load('linear_regression_final_model.joblib')

# Récupérer les colonnes de X_train pour s'assurer de l'ordre et des colonnes présentes
feature_columns = X_train.columns

# Définir les variables catégorielles (doit correspondre à la liste utilisée pour l'entraînement)
colonnes_categoriques = ['status', 'branch_name', 'repo_name', 'env_type', 'error_tag']

# --- Préparation de la nouvelle donnée pour la prédiction ---

# 2. Créer un DataFrame pour le nouveau point de donnée avec les colonnes originales
new_observation_raw = pd.DataFrame({
    'code_lines_changed': [500],
    'status': ['success'], # Valeur réelle pour 'status'
    'branch_name': ['develop'], # Valeur réelle pour 'branch_name'
    'repo_name': ['repo-api'], # Valeur réelle pour 'repo_name'
    'env_type': ['dev'], # Valeur réelle pour 'env_type'
    'error_tag': ['None'] # Valeur réelle pour 'error_tag'
})

# 3. Appliquer le One-Hot Encoding au nouveau point de donnée, avec drop_first=True
new_observation_encoded = pd.get_dummies(new_observation_raw, columns=colonnes_categoriques, drop_first=True)

# 4. Aligner les colonnes du nouveau point de donnée encodé avec les colonnes utilisées pour l'entraînement (X_train)
# Les colonnes manquantes seront remplies avec 0, et les colonnes supplémentaires (si elles apparaissent en raison de get_dummies)
# qui n'étaient pas dans X_train seront supprimées.
new_data_point = new_observation_encoded.reindex(columns=feature_columns, fill_value=0)

# Assurez-vous que toutes les colonnes numériques sont du bon type pour correspondre à X_train
for col in feature_columns:
    if col in new_data_point.columns:
        new_data_point[col] = new_data_point[col].astype(X_train[col].dtype)

# 5. Exécuter la prédiction sur la nouvelle ligne de données
predicted_duration = model_loaded.predict(new_data_point)

# 6. Afficher le résultat
print("\n--- Résultat de la Prédiction ---")
print(f"Durée prédite du pipeline avec 500 lignes de changement : {predicted_duration[0]:.2f} secondes")
print(f"Soit environ {predicted_duration[0] / 60:.2f} minutes.")